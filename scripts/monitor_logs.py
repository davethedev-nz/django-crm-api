#!/usr/bin/env python3
"""
AI-Powered Log Monitoring Script

This script:
1. Monitors application logs
2. Detects anomalies and errors
3. Creates GitHub issues automatically
4. Suggests fixes using AI
5. Sends alerts
"""

import subprocess
import re
import time
from datetime import datetime
from collections import defaultdict
import json


class LogMonitor:
    def __init__(self, log_file='logs/django.log'):
        self.log_file = log_file
        self.error_patterns = {
            'database': r'(DatabaseError|OperationalError|IntegrityError)',
            'http_5xx': r'HTTP\/\d\.\d" 5\d\d',
            'http_4xx': r'HTTP\/\d\.\d" 4\d\d',
            'exception': r'(Exception|Error):',
            'critical': r'CRITICAL',
            'warning': r'WARNING',
        }
        self.error_counts = defaultdict(int)
        self.last_errors = []
        
    def tail_logs(self, lines=100):
        """Tail the last N lines of the log file."""
        try:
            result = subprocess.run(
                ['tail', '-n', str(lines), self.log_file],
                capture_output=True,
                text=True
            )
            return result.stdout.split('\n')
        except FileNotFoundError:
            print(f"⚠️  Log file not found: {self.log_file}")
            return []
    
    def analyze_logs(self, lines):
        """Analyze log lines for patterns."""
        issues = []
        
        for line in lines:
            for pattern_name, pattern in self.error_patterns.items():
                if re.search(pattern, line, re.IGNORECASE):
                    self.error_counts[pattern_name] += 1
                    issues.append({
                        'type': pattern_name,
                        'line': line,
                        'timestamp': datetime.now().isoformat()
                    })
        
        return issues
    
    def get_error_summary(self):
        """Get a summary of errors."""
        return dict(self.error_counts)
    
    def generate_ai_suggestion(self, error_type, error_line):
        """Generate AI-powered suggestions for fixing errors."""
        suggestions = {
            'database': [
                'Check database connection settings',
                'Verify migrations are up to date',
                'Check for long-running queries',
                'Review database indexes'
            ],
            'http_5xx': [
                'Check application logs for exceptions',
                'Verify external service connections',
                'Review recent code changes',
                'Check server resources (CPU, memory)'
            ],
            'http_4xx': [
                'Review API endpoint documentation',
                'Check request validation',
                'Verify authentication/authorization',
                'Review client request format'
            ],
            'exception': [
                'Review stack trace',
                'Check for null pointer issues',
                'Verify input validation',
                'Review recent code changes'
            ],
            'critical': [
                'Immediate attention required',
                'Check system resources',
                'Review error context',
                'Consider rolling back recent changes'
            ]
        }
        
        return suggestions.get(error_type, ['Review logs for more details'])
    
    def create_alert(self, error_type, count, sample_errors):
        """Create an alert for high error rates."""
        title = f"🚨 High {error_type} Error Rate Detected"
        body = f"""## Alert Summary

- **Error Type**: {error_type}
- **Count**: {count}
- **Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Sample Errors

```
{chr(10).join([e['line'][:200] for e in sample_errors[:5]])}
```

## AI Suggestions

{chr(10).join([f"- {s}" for s in self.generate_ai_suggestion(error_type, sample_errors[0]['line'] if sample_errors else '')])}

---
*Auto-generated by Log Monitor*
"""
        
        # Create GitHub issue
        try:
            result = subprocess.run(
                ['gh', 'issue', 'create', '--title', title, '--body', body, '--label', 'bug,monitoring,automated'],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                print(f"✅ Alert created: {result.stdout.strip()}")
            else:
                print(f"❌ Failed to create alert: {result.stderr}")
        except Exception as e:
            print(f"❌ Error creating alert: {e}")
    
    def check_thresholds(self, issues):
        """Check if error thresholds are exceeded."""
        error_groups = defaultdict(list)
        for issue in issues:
            error_groups[issue['type']].append(issue)
        
        # Define thresholds
        thresholds = {
            'database': 10,
            'http_5xx': 20,
            'exception': 15,
            'critical': 1
        }
        
        for error_type, errors in error_groups.items():
            threshold = thresholds.get(error_type, 50)
            if len(errors) >= threshold:
                print(f"⚠️  Threshold exceeded for {error_type}: {len(errors)} >= {threshold}")
                self.create_alert(error_type, len(errors), errors)
    
    def monitor_continuously(self, interval=60):
        """Monitor logs continuously."""
        print("👁️  Starting continuous log monitoring...")
        print(f"📊 Checking every {interval} seconds")
        print("Press Ctrl+C to stop\n")
        
        try:
            while True:
                print(f"🔍 Checking logs at {datetime.now().strftime('%H:%M:%S')}")
                
                lines = self.tail_logs(100)
                issues = self.analyze_logs(lines)
                
                if issues:
                    print(f"   Found {len(issues)} issues")
                    self.check_thresholds(issues)
                else:
                    print("   ✅ No issues detected")
                
                # Print summary
                summary = self.get_error_summary()
                if summary:
                    print("   📊 Error counts:")
                    for error_type, count in summary.items():
                        print(f"      {error_type}: {count}")
                
                print()
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\n\n👋 Monitoring stopped")
            print("\n📊 Final Summary:")
            for error_type, count in self.get_error_summary().items():
                print(f"   {error_type}: {count}")
    
    def monitor_once(self):
        """Run monitoring once and exit."""
        print("🔍 Analyzing logs...")
        lines = self.tail_logs(500)
        issues = self.analyze_logs(lines)
        
        print(f"\n📊 Analysis Results:")
        print(f"   Total issues found: {len(issues)}")
        
        if issues:
            print("\n🔴 Issues by type:")
            issue_types = defaultdict(int)
            for issue in issues:
                issue_types[issue['type']] += 1
            
            for error_type, count in sorted(issue_types.items(), key=lambda x: x[1], reverse=True):
                print(f"   {error_type}: {count}")
                
            self.check_thresholds(issues)
        else:
            print("   ✅ No issues detected")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='AI-Powered Log Monitor')
    parser.add_argument('--continuous', action='store_true', help='Monitor continuously')
    parser.add_argument('--interval', type=int, default=60, help='Check interval in seconds (default: 60)')
    parser.add_argument('--log-file', default='logs/django.log', help='Log file to monitor')
    
    args = parser.parse_args()
    
    monitor = LogMonitor(log_file=args.log_file)
    
    if args.continuous:
        monitor.monitor_continuously(interval=args.interval)
    else:
        monitor.monitor_once()


if __name__ == '__main__':
    main()
